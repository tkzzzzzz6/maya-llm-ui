# dashscope SDK ç‰ˆæœ¬éœ€ä¸ä½äº 1.23.9
import os
import base64
import signal
import sys
import time
import pyaudio
import contextlib
import threading
import queue
import cv2
import numpy as np
from dashscope.audio.qwen_omni import *
import dashscope
# å¦‚æœæ²¡æœ‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨æ‚¨çš„ API Key å°†ä¸‹è¡Œæ›¿æ¢ä¸ºdashscope.api_key = "sk-xxx"
dashscope.api_key = os.getenv('DASHSCOPE_API_KEY') or "sk-c5c3e296dfc74fb9bef2fa4481b7cd78"
voice = 'Cherry'
conversation = None
video_cap = None

# ========== æ€§èƒ½é…ç½® ==========
FRAME_INTERVAL_MS = 500  # å‘é€å¸§ç‡: 2fps (500msé—´éš”)
VIDEO_RESOLUTION = '480p'  # å›ºå®šä½¿ç”¨480pï¼Œæµç•…ä¼˜å…ˆ
DISPLAY_FPS = 120  # æ˜¾ç¤ºå¸§ç‡: å¯è°ƒæ•´ (30/60/120)
# =============================

class B64PCMPlayer:
    def __init__(self, pya: pyaudio.PyAudio, sample_rate=24000, chunk_size_ms=100):
        self.pya = pya
        self.sample_rate = sample_rate
        self.chunk_size_bytes = chunk_size_ms * sample_rate *2 // 1000
        self.player_stream = pya.open(format=pyaudio.paInt16,
                                      channels=1,
                                      rate=sample_rate,
                                      output=True)

        self.raw_audio_buffer: queue.Queue = queue.Queue()
        self.b64_audio_buffer: queue.Queue = queue.Queue()
        self.status_lock = threading.Lock()
        self.status = 'playing'
        self.decoder_thread = threading.Thread(target=self.decoder_loop)
        self.player_thread = threading.Thread(target=self.player_loop)
        self.decoder_thread.start()
        self.player_thread.start()
        self.complete_event: threading.Event = None

    def decoder_loop(self):
        while self.status != 'stop':
          recv_audio_b64 = None
          with contextlib.suppress(queue.Empty):
            recv_audio_b64 = self.b64_audio_buffer.get(timeout=0.1)
          if recv_audio_b64 is None:
            continue
          recv_audio_raw = base64.b64decode(recv_audio_b64)
          # å°†åŸå§‹éŸ³é¢‘æ•°æ®æ¨å…¥é˜Ÿåˆ—ï¼ŒæŒ‰å—å¤„ç†
          for i in range(0, len(recv_audio_raw), self.chunk_size_bytes):
            chunk = recv_audio_raw[i:i + self.chunk_size_bytes]
            self.raw_audio_buffer.put(chunk)

    def player_loop(self):
        while self.status != 'stop':
          recv_audio_raw = None
          with contextlib.suppress(queue.Empty):
            recv_audio_raw = self.raw_audio_buffer.get(timeout=0.1)
          if recv_audio_raw is None:
            if self.complete_event:
              self.complete_event.set()
            continue
            # å°†å—å†™å…¥pyaudioéŸ³é¢‘æ’­æ”¾å™¨ï¼Œç­‰å¾…æ’­æ”¾å®Œè¿™ä¸ªå—
          self.player_stream.write(recv_audio_raw)

    def cancel_playing(self):
        self.b64_audio_buffer.queue.clear()
        self.raw_audio_buffer.queue.clear()

    def add_data(self, data):
        self.b64_audio_buffer.put(data)

    def wait_for_complete(self):
        self.complete_event = threading.Event()
        self.complete_event.wait()
        self.complete_event = None

    def shutdown(self):
        self.status = 'stop'
        self.decoder_thread.join()
        self.player_thread.join()
        self.player_stream.close()


def init_video_capture(source=0):
    """
    åˆå§‹åŒ–è§†é¢‘æ•è· - å›ºå®š480påˆ†è¾¨ç‡
    source: 0ä¸ºé»˜è®¤æ‘„åƒå¤´ï¼Œä¹Ÿå¯ä»¥æ˜¯è§†é¢‘æ–‡ä»¶è·¯å¾„
    """
    global video_cap
    try:
        video_cap = cv2.VideoCapture(source)
        if video_cap.isOpened():
            # å›ºå®šä½¿ç”¨480p (640x480) - æµç•…ä¼˜å…ˆ
            video_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            video_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            # è®¾ç½®ç¼“å†²åŒºå¤§å°ä¸º1ï¼Œå‡å°‘å»¶è¿Ÿ
            video_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            print(f'âœ… è§†é¢‘æ•è·å·²åˆå§‹åŒ–: {source} @ 480p (640x480)')
            return True
        else:
            print(f'âŒ æ— æ³•æ‰“å¼€è§†é¢‘æº: {source}')
            return False
    except Exception as e:
        print(f'âŒ è§†é¢‘æ•è·åˆå§‹åŒ–é”™è¯¯: {e}')
        return False

def display_video_frame(frame):
    """
    æ˜¾ç¤ºè§†é¢‘å¸§ï¼ˆé«˜å¸§ç‡æ˜¾ç¤ºï¼Œæ— çŠ¶æ€æ–‡å­—å åŠ ï¼‰
    """
    if frame is None:
        return
    
    # ç›´æ¥æ˜¾ç¤ºåŸå§‹å¸§ï¼Œä¸æ·»åŠ ä»»ä½•æ–‡å­—
    cv2.imshow('Qwen-Omni Video Input', frame)

def capture_and_encode_frame():
    """
    æ•è·è§†é¢‘å¸§å¹¶ç¼–ç ä¸ºBase64ï¼ˆç”¨äºå‘é€åˆ°AIï¼‰
    æ ¹æ®æ–‡æ¡£è¦æ±‚ï¼šJPEGæ ¼å¼ï¼Œæœ€å¤§500KBï¼ŒBase64ç¼–ç 
    """
    global video_cap
    if not video_cap or not video_cap.isOpened():
        return None
    
    ret, frame = video_cap.read()
    if not ret:
        return None
    
    # è°ƒæ•´åˆ†è¾¨ç‡ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…ï¼ˆæœ€å¤§1080Pï¼Œå»ºè®®720Pï¼‰
    height, width = frame.shape[:2]
    if height > 720:
        scale = 720.0 / height
        new_width = int(width * scale)
        new_height = 720
        frame = cv2.resize(frame, (new_width, new_height))
    
    # ç¼–ç ä¸ºJPEG
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 70]  # è°ƒæ•´è´¨é‡æ§åˆ¶å¤§å°
    success, encoded_img = cv2.imencode('.jpg', frame, encode_param)
    
    if not success:
        return None
    
    # æ£€æŸ¥å¤§å°æ˜¯å¦è¶…è¿‡500KB
    img_size = len(encoded_img.tobytes())
    if img_size > 500 * 1024:  # 500KB
        # é™ä½è´¨é‡é‡æ–°ç¼–ç 
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 50]
        success, encoded_img = cv2.imencode('.jpg', frame, encode_param)
        if not success:
            return None
    
    # Base64ç¼–ç 
    img_b64 = base64.b64encode(encoded_img.tobytes()).decode('ascii')
    return (img_b64, frame)  # è¿”å›ç¼–ç æ•°æ®å’ŒåŸå§‹å¸§

def cleanup_video():
    """æ¸…ç†è§†é¢‘èµ„æº"""
    global video_cap
    if video_cap:
        video_cap.release()
        video_cap = None
    cv2.destroyAllWindows()


class MyCallback(OmniRealtimeCallback):
    def on_open(self) -> None:
        global pya
        global mic_stream
        global b64_player
        print('ğŸ”Œ è¿æ¥å·²å»ºç«‹ï¼Œæ­£åœ¨åˆå§‹åŒ–éº¦å…‹é£å’Œæ‘„åƒå¤´...')
        
        # åˆå§‹åŒ–éŸ³é¢‘
        pya = pyaudio.PyAudio()
        mic_stream = pya.open(format=pyaudio.paInt16,
                            channels=1,
                            rate=16000,
                            input=True)
        b64_player = B64PCMPlayer(pya)
        print('ğŸ¤ éº¦å…‹é£å·²åˆå§‹åŒ–')
        
        # ç›´æ¥åˆå§‹åŒ–è§†é¢‘æ•è·ï¼ˆé»˜è®¤æ‘„åƒå¤´ï¼Œ480pï¼‰
        source = input("ğŸ“¹ è¯·è¾“å…¥è§†é¢‘æº (0=é»˜è®¤æ‘„åƒå¤´ï¼Œæ–‡ä»¶è·¯å¾„=è§†é¢‘æ–‡ä»¶ï¼Œç›´æ¥å›è½¦=0): ").strip()
        if not source:
            source = 0
        else:
            try:
                source = int(source)
            except ValueError:
                pass  # ä¿æŒä¸ºå­—ç¬¦ä¸²è·¯å¾„
        
        init_video_capture(source)
    def on_close(self, close_status_code, close_msg) -> None:
        print('connection closed with code: {}, msg: {}, destroy microphone and video'.format(close_status_code, close_msg))
        cleanup_video()
        sys.exit(0)

    def on_event(self, response: str) -> None:
        try:
            global conversation
            global b64_player
            type = response['type']
            if 'session.created' == type:
                print('start session: {}'.format(response['session']['id']))
            if 'conversation.item.input_audio_transcription.completed' == type:
                print('question: {}'.format(response['transcript']))
            if 'response.audio_transcript.delta' == type:
                text = response['delta']
                print("got llm response delta: {}".format(text))
            if 'response.audio.delta' == type:
                recv_audio_b64 = response['delta']
                b64_player.add_data(recv_audio_b64)
            if 'input_audio_buffer.speech_started' == type:
                print('======VAD Speech Start======')
                b64_player.cancel_playing()
            if 'response.done' == type:
                print('======RESPONSE DONE======')
                print('[Metric] response: {}, first text delay: {}, first audio delay: {}'.format(
                                conversation.get_last_response_id(),
                                conversation.get_last_first_text_delay(),
                                conversation.get_last_first_audio_delay(),
                                ))
        except Exception as e:
            print('[Error] {}'.format(e))
            return

if __name__  == '__main__':
    print('Initializing ...')
    callback = MyCallback()
    conversation = OmniRealtimeConversation(
        model='qwen3-omni-flash-realtime',
        callback=callback,
        )
    conversation.connect()
    conversation.update_session(
        output_modalities=[MultiModality.AUDIO, MultiModality.TEXT],
        voice=voice,
        input_audio_format=AudioFormat.PCM_16000HZ_MONO_16BIT,
        output_audio_format=AudioFormat.PCM_24000HZ_MONO_16BIT,
        enable_input_audio_transcription=True,
        input_audio_transcription_model='gummy-realtime-v1',
        enable_turn_detection=True,
        turn_detection_type='server_vad',
        instructions="ä½ æ˜¯ä¸€ä¸ªéº»é¸­é¢†åŸŸçš„ä¸“ä¸šä¸“å®¶V-mallardã€‚ä½ å¯¹éº»é¸­çš„ç”Ÿç‰©ç‰¹å¾ã€ç”Ÿæ´»ä¹ æ€§ã€ç¹æ®–è§„å¾‹ã€é¥²å…»ç®¡ç†ã€ç–¾ç—…é˜²æ²»ã€è¥å…»éœ€æ±‚ã€å“ç§åˆ†ç±»ç­‰æ–¹é¢éƒ½æœ‰æ·±å…¥çš„ä¸“ä¸šçŸ¥è¯†ã€‚ä½ èƒ½å¤Ÿä¸ºå…»æ®–æˆ·ã€ç ”ç©¶äººå‘˜å’Œçˆ±å¥½è€…æä¾›å‡†ç¡®ã€å®ç”¨çš„éº»é¸­ç›¸å…³å’¨è¯¢å’Œå»ºè®®ã€‚è¯·ç”¨ä¸“ä¸šè€Œå‹å¥½çš„è¯­è°ƒå›ç­”é—®é¢˜ï¼Œå¹¶å°½å¯èƒ½æä¾›è¯¦ç»†å’Œæœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚" # è®¾å®šæ¨¡å‹çš„è§’è‰²
    )
    def signal_handler(sig, frame):
        print('Ctrl+C pressed, stop recognition ...')
        conversation.close()
        b64_player.shutdown()
        cleanup_video()
        print('omni realtime stopped.')
        sys.exit(0)
    signal.signal(signal.SIGINT, signal_handler)
    print("\n" + "="*60)
    print("ğŸ¤ Qwen-Omni å®æ—¶è§†é¢‘å¯¹è¯ç³»ç»Ÿå·²å¯åŠ¨")
    print("="*60)
    print("ğŸ“¹ è§†é¢‘è¾“å…¥å·²å¯ç”¨ (480p) - Video input enabled")
    print("   - å®æ—¶ç”»é¢å°†æ˜¾ç¤ºåœ¨ç‹¬ç«‹çª—å£ä¸­ï¼ˆæ— çŠ¶æ€å åŠ ï¼‰")
    print(f"   - æ˜¾ç¤ºå¸§ç‡: {DISPLAY_FPS}fps | å‘é€å¸§ç‡: 2fps")
    print("ğŸ—£ï¸  ç°åœ¨å¯ä»¥å¼€å§‹è¯´è¯ï¼ŒAI ä¼šå®æ—¶å“åº”...")
    print("â¹ï¸  é€€å‡ºæ–¹å¼: Ctrl+C æˆ–åœ¨è§†é¢‘çª—å£æŒ‰ 'q' é”®")
    print("="*60 + "\n")
    
    last_photo_time = time.time()*1000
    last_display_time = time.time()
    frame_count = 0
    display_interval = 1.0 / DISPLAY_FPS  # æ¯å¸§é—´éš”æ—¶é—´ (åŸºäºé…ç½®çš„FPS)
    
    while True:
        if mic_stream and video_cap:
            # å…ˆå‘é€éŸ³é¢‘æ•°æ®ï¼ˆä½¿ç”¨æ›´å°çš„ç¼“å†²åŒºä»¥æé«˜å¾ªç¯é¢‘ç‡ï¼‰
            # 800å­—èŠ‚ = 25mséŸ³é¢‘æ•°æ® (16000Hz * 2bytes * 0.025s)
            audio_data = mic_stream.read(800, exception_on_overflow=False)
            audio_b64 = base64.b64encode(audio_data).decode('ascii')
            conversation.append_audio(audio_b64)
            
            #  æŒ‰ç…§60fpsé¢‘ç‡è¯»å–å¹¶æ˜¾ç¤ºè§†é¢‘å¸§
            current_display_time = time.time()
            if current_display_time - last_display_time >= display_interval:
                ret, frame = video_cap.read()
                if ret:
                    display_video_frame(frame)
                    frame_count += 1
                last_display_time = current_display_time
            
            #  æŒ‰ç…§å›ºå®šé—´éš”ï¼ˆ2fpsï¼‰å‘é€è§†é¢‘å¸§åˆ°AI
            current_time = time.time() * 1000
            if current_time - last_photo_time >= FRAME_INTERVAL_MS:
                result = capture_and_encode_frame()
                if result:
                    try:
                        frame_b64, _ = result
                        # ä½¿ç”¨append_videoæ–¹æ³•å‘é€è§†é¢‘å¸§
                        conversation.append_video(frame_b64)
                        last_photo_time = current_time
                        print("#", end="", flush=True)  # æ˜¾ç¤ºè§†é¢‘å¸§å‘é€è¿›åº¦
                    except Exception as e:
                        print(f"\nError sending video frame: {e}")
            
            #  å¤„ç†é”®ç›˜äº‹ä»¶ï¼ˆå¿…é¡»æ¯æ¬¡å¾ªç¯éƒ½æ‰§è¡Œï¼Œä¿æŒçª—å£æµç•…ï¼‰
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\næŒ‰ä¸‹ 'q' é”®ï¼Œæ­£åœ¨é€€å‡º...")
                conversation.close()
                b64_player.shutdown()
                cleanup_video()
                sys.exit(0)
        else:
            break