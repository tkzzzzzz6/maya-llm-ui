import { useState, useRef, useCallback, useEffect } from "react"
import { toast } from "sonner"

export interface VideoRealtimeHandlerReturn {
  // çŠ¶æ€
  isConnected: boolean
  isStreaming: boolean
  currentResponse: string
  currentTranscript: string
  availableCameras: MediaDeviceInfo[]
  selectedCameraId: string | null

  // æ§åˆ¶
  connect: () => Promise<void>
  disconnect: () => void
  startStreaming: (cameraId?: string) => Promise<void>
  stopStreaming: () => void
  selectCamera: (deviceId: string) => void
  refreshCameras: () => Promise<void>

  // å›è°ƒ
  onResponse?: (text: string) => void
  onAudio?: (audioBlob: Blob) => void
}

interface VideoRealtimeHandlerOptions {
  onResponse?: (text: string) => void
  onAudio?: (audioBlob: Blob) => void
  onError?: (error: Error) => void
}

export function useVideoRealtime(
  options?: VideoRealtimeHandlerOptions
): VideoRealtimeHandlerReturn {
  const [isConnected, setIsConnected] = useState(false)
  const [isStreaming, setIsStreaming] = useState(false)
  const [currentResponse, setCurrentResponse] = useState("")
  const [currentTranscript, setCurrentTranscript] = useState("")

  const wsRef = useRef<WebSocket | null>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const videoIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const audioWorkletRef = useRef<AudioWorkletNode | null>(null)

  // è¿æ¥ WebSocket
  const connect = useCallback(async () => {
    try {
      // è·å– WebSocket URL - æ”¯æŒå¤šç§æ–¹å¼
      let wsUrl = process.env.NEXT_PUBLIC_QWEN_VIDEO_WS_URL

      console.log("ğŸ” ç¯å¢ƒå˜é‡:", process.env.NEXT_PUBLIC_QWEN_VIDEO_WS_URL)
      console.log("ğŸŒ å½“å‰ä¸»æœº:", window.location.hostname)

      if (!wsUrl) {
        // å¦‚æœæ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨å½“å‰é¡µé¢çš„ä¸»æœºå
        const protocol = window.location.protocol === "https:" ? "wss:" : "ws:"
        const hostname = window.location.hostname
        // é»˜è®¤ä½¿ç”¨ 5003 ç«¯å£
        wsUrl = `${protocol}//${hostname}:5003/ws/video`
        console.log("âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆåœ°å€")
      } else {
        console.log("âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„åœ°å€")
      }

      console.log("ğŸ“¡ è¿æ¥åˆ°å®æ—¶è§†é¢‘æœåŠ¡:", wsUrl)

      const ws = new WebSocket(wsUrl)

      ws.onopen = () => {
        console.log("WebSocket è¿æ¥æˆåŠŸ")
        setIsConnected(true)
        toast.success("å®æ—¶è§†é¢‘æœåŠ¡å·²è¿æ¥")
      }

      ws.onmessage = event => {
        try {
          const data = JSON.parse(event.data)

          switch (data.type) {
            case "ready":
              console.log("ä¼šè¯å·²å°±ç»ª:", data.session_id)
              break

            case "text.delta":
              // æ¥æ”¶æ–‡æœ¬å“åº”
              setCurrentResponse(prev => prev + data.text)
              options?.onResponse?.(data.text)
              break

            case "audio.delta":
              // æ¥æ”¶éŸ³é¢‘å“åº”
              if (data.audio) {
                const audioBlob = base64ToBlob(data.audio, "audio/pcm")
                options?.onAudio?.(audioBlob)
              }
              break

            case "transcript":
              // è¯­éŸ³è½¬å½•
              setCurrentTranscript(data.text)
              console.log("è¯­éŸ³è½¬å½•:", data.text)
              break

            case "speech.started":
              console.log("æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
              break

            case "response.done":
              console.log("å“åº”å®Œæˆ")
              break

            case "error":
              console.error("æœåŠ¡å™¨é”™è¯¯:", data.message)
              toast.error(data.message)
              break
          }
        } catch (error) {
          console.error("è§£ææ¶ˆæ¯å¤±è´¥:", error)
        }
      }

      ws.onerror = error => {
        console.error("WebSocket é”™è¯¯:", error)
        toast.error("å®æ—¶è§†é¢‘æœåŠ¡è¿æ¥é”™è¯¯")
        const errorObj = new Error("WebSocket connection error")
        options?.onError?.(errorObj)
      }

      ws.onclose = () => {
        console.log("WebSocket è¿æ¥å…³é—­")
        setIsConnected(false)
        setIsStreaming(false)
      }

      wsRef.current = ws
    } catch (error: any) {
      console.error("è¿æ¥å¤±è´¥:", error)
      toast.error("æ— æ³•è¿æ¥åˆ°å®æ—¶è§†é¢‘æœåŠ¡")
      options?.onError?.(error)
    }
  }, [options])

  // æ–­å¼€è¿æ¥
  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.send(JSON.stringify({ type: "close" }))
      wsRef.current.close()
      wsRef.current = null
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }

    if (videoIntervalRef.current) {
      clearInterval(videoIntervalRef.current)
      videoIntervalRef.current = null
    }

    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }

    setIsConnected(false)
    setIsStreaming(false)
  }, [])

  // å¼€å§‹æµå¼ä¼ è¾“
  const startStreaming = useCallback(async () => {
    if (!isConnected || !wsRef.current) {
      toast.error("è¯·å…ˆè¿æ¥æœåŠ¡")
      return
    }

    try {
      // è·å–æ‘„åƒå¤´å’Œéº¦å…‹é£
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: "user"
        },
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000
        }
      })

      streamRef.current = stream
      setIsStreaming(true)

      // å®šæ—¶å‘é€è§†é¢‘å¸§ï¼ˆ2fpsï¼‰
      const videoTrack = stream.getVideoTracks()[0]
      // @ts-ignore - ImageCapture API å¯èƒ½ä¸åœ¨æ‰€æœ‰ç±»å‹å®šä¹‰ä¸­
      const imageCapture = new ImageCapture(videoTrack)

      videoIntervalRef.current = setInterval(async () => {
        try {
          // @ts-ignore - grabFrame æ–¹æ³•ç±»å‹å®šä¹‰
          const bitmap = await imageCapture.grabFrame()

          // è½¬æ¢ä¸º JPEG
          const canvas = document.createElement("canvas")
          canvas.width = bitmap.width
          canvas.height = bitmap.height
          const ctx = canvas.getContext("2d")
          ctx?.drawImage(bitmap, 0, 0)

          canvas.toBlob(
            blob => {
              if (blob && wsRef.current) {
                const reader = new FileReader()
                reader.onload = () => {
                  const base64 = (reader.result as string).split(",")[1]
                  wsRef.current?.send(
                    JSON.stringify({
                      type: "video",
                      data: base64
                    })
                  )
                }
                reader.readAsDataURL(blob)
              }
            },
            "image/jpeg",
            0.7
          )
        } catch (error) {
          console.error("æ•è·è§†é¢‘å¸§å¤±è´¥:", error)
        }
      }, 500) // 2fps

      // å®æ—¶å‘é€éŸ³é¢‘
      const audioTrack = stream.getAudioTracks()[0]
      const audioContext = new AudioContext({ sampleRate: 16000 })
      audioContextRef.current = audioContext

      const source = audioContext.createMediaStreamSource(
        new MediaStream([audioTrack])
      )

      // ä½¿ç”¨ ScriptProcessorNode å¤„ç†éŸ³é¢‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
      const processor = audioContext.createScriptProcessor(4096, 1, 1)
      processor.onaudioprocess = e => {
        if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
          const inputData = e.inputBuffer.getChannelData(0)

          // è½¬æ¢ä¸º 16-bit PCM
          const pcm = new Int16Array(inputData.length)
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]))
            pcm[i] = s < 0 ? s * 0x8000 : s * 0x7fff
          }

          // è½¬ä¸º Base64
          const base64 = arrayBufferToBase64(pcm.buffer)

          wsRef.current.send(
            JSON.stringify({
              type: "audio",
              data: base64
            })
          )
        }
      }

      source.connect(processor)
      processor.connect(audioContext.destination)

      toast.success("å¼€å§‹å®æ—¶æµå¼ä¼ è¾“")
    } catch (error: any) {
      console.error("å¼€å§‹æµå¼ä¼ è¾“å¤±è´¥:", error)
      toast.error("æ— æ³•è®¿é—®æ‘„åƒå¤´æˆ–éº¦å…‹é£")
      options?.onError?.(error)
    }
  }, [isConnected, options])

  // åœæ­¢æµå¼ä¼ è¾“
  const stopStreaming = useCallback(() => {
    if (videoIntervalRef.current) {
      clearInterval(videoIntervalRef.current)
      videoIntervalRef.current = null
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }

    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }

    setIsStreaming(false)
    toast.info("åœæ­¢æµå¼ä¼ è¾“")
  }, [])

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      disconnect()
    }
  }, [disconnect])

  return {
    isConnected,
    isStreaming,
    currentResponse,
    currentTranscript,
    availableCameras: [], // TODO: å®ç°æ‘„åƒå¤´ç®¡ç†
    selectedCameraId: null,
    connect,
    disconnect,
    startStreaming,
    stopStreaming,
    selectCamera: (deviceId: string) => {}, // TODO: å®ç°æ‘„åƒå¤´é€‰æ‹©
    refreshCameras: async () => {}, // TODO: å®ç°åˆ·æ–°æ‘„åƒå¤´
    onResponse: options?.onResponse,
    onAudio: options?.onAudio
  }
}

// å·¥å…·å‡½æ•°
function base64ToBlob(base64: string, mimeType: string): Blob {
  const byteCharacters = atob(base64)
  const byteNumbers = new Array(byteCharacters.length)
  for (let i = 0; i < byteCharacters.length; i++) {
    byteNumbers[i] = byteCharacters.charCodeAt(i)
  }
  const byteArray = new Uint8Array(byteNumbers)
  return new Blob([byteArray], { type: mimeType })
}

function arrayBufferToBase64(buffer: ArrayBuffer): string {
  const bytes = new Uint8Array(buffer)
  let binary = ""
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i])
  }
  return btoa(binary)
}
