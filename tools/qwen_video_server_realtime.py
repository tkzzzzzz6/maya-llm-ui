"""
Qwen-Omni è§†é¢‘æœåŠ¡ API - å®æ—¶æµå¼ç‰ˆæœ¬
å‚è€ƒ vad_dash.py çš„è®¾è®¡ï¼Œæ”¯æŒå®æ—¶è§†é¢‘+éŸ³é¢‘æµå¤„ç†
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_sock import Sock
import os
import json
import base64
import logging
import threading
import queue
import time
import cv2
import numpy as np
from dashscope.audio.qwen_omni import *
import dashscope

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)
sock = Sock(app)

# Dashscope API é…ç½®
dashscope.api_key = os.getenv('DASHSCOPE_API_KEY') or "sk-c5c3e296dfc74fb9bef2fa4481b7cd78"

OUTPUT_DIR = "./qwen_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# æ€§èƒ½é…ç½®ï¼ˆå‚è€ƒ vad_dash.pyï¼‰
FRAME_INTERVAL_MS = 500  # å‘é€å¸§ç‡: 2fps
VIDEO_RESOLUTION = '480p'

# ä¼šè¯ç®¡ç†
sessions = {}
session_lock = threading.Lock()


class RealtimeVideoSession:
    """å®æ—¶è§†é¢‘åˆ†æä¼šè¯ - å‚è€ƒ vad_dash.py"""

    def __init__(self, session_id, websocket, instructions="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§†é¢‘åˆ†æåŠ©æ‰‹"):
        self.session_id = session_id
        self.websocket = websocket
        self.instructions = instructions
        self.conversation = None
        self.is_active = False
        self.last_frame_time = 0
        self.response_queue = queue.Queue()

    def start(self):
        """å¯åŠ¨å®æ—¶ä¼šè¯"""
        try:
            logger.info(f"å¯åŠ¨å®æ—¶ä¼šè¯: {self.session_id}")

            # åˆ›å»ºå›è°ƒ
            callback = self._create_callback()

            # åˆ›å»ºå¯¹è¯å®ä¾‹
            self.conversation = OmniRealtimeConversation(
                model='qwen3-omni-flash-realtime',
                callback=callback,
            )

            # å»ºç«‹è¿æ¥
            self.conversation.connect()

            # æ›´æ–°ä¼šè¯é…ç½®ï¼ˆå¯ç”¨ VADï¼Œå‚è€ƒ vad_dash.pyï¼‰
            self.conversation.update_session(
                voice='Cherry',
                output_modalities=[MultiModality.AUDIO, MultiModality.TEXT],  # åŒæ—¶è¿”å›éŸ³é¢‘å’Œæ–‡æœ¬
                input_audio_format=AudioFormat.PCM_16000HZ_MONO_16BIT,
                output_audio_format=AudioFormat.PCM_24000HZ_MONO_16BIT,
                enable_input_audio_transcription=True,  # å¯ç”¨éŸ³é¢‘è½¬å½•
                input_audio_transcription_model='gummy-realtime-v1',
                enable_turn_detection=True,  # å¯ç”¨ VAD
                turn_detection_type='server_vad',  # æœåŠ¡ç«¯ VAD
                instructions=self.instructions
            )

            self.is_active = True
            logger.info(f"å®æ—¶ä¼šè¯ {self.session_id} å¯åŠ¨æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"ä¼šè¯å¯åŠ¨å¤±è´¥: {e}", exc_info=True)
            return False

    def _create_callback(self):
        """åˆ›å»ºå›è°ƒå¤„ç†å™¨ - å‚è€ƒ vad_dash.py"""
        session = self

        class SessionCallback(OmniRealtimeCallback):
            def on_open(self):
                logger.info(f"ä¼šè¯ {session.session_id} è¿æ¥å·²å»ºç«‹")
                session._send_to_client({
                    'type': 'session.opened',
                    'session_id': session.session_id
                })

            def on_close(self, close_status_code, close_msg):
                logger.info(f"ä¼šè¯ {session.session_id} å…³é—­: {close_status_code}")
                session.is_active = False

            def on_event(self, response: str):
                try:
                    event_type = response.get('type', '')

                    if event_type == 'session.created':
                        logger.info(f"ä¼šè¯åˆ›å»º: {response['session']['id']}")

                    elif event_type == 'conversation.item.input_audio_transcription.completed':
                        transcript = response.get('transcript', '')
                        logger.info(f"è¯­éŸ³è½¬å½•: {transcript}")
                        session._send_to_client({
                            'type': 'transcript',
                            'text': transcript
                        })

                    elif event_type == 'response.audio_transcript.delta':
                        delta = response.get('delta', '')
                        session._send_to_client({
                            'type': 'text.delta',
                            'text': delta
                        })

                    elif event_type == 'response.audio.delta':
                        audio_b64 = response.get('delta', '')
                        session._send_to_client({
                            'type': 'audio.delta',
                            'audio': audio_b64
                        })

                    elif event_type == 'input_audio_buffer.speech_started':
                        logger.info("æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                        session._send_to_client({
                            'type': 'speech.started'
                        })

                    elif event_type == 'response.done':
                        logger.info("å“åº”å®Œæˆ")
                        session._send_to_client({
                            'type': 'response.done'
                        })

                except Exception as e:
                    logger.error(f"äº‹ä»¶å¤„ç†é”™è¯¯: {e}")

        return SessionCallback()

    def _send_to_client(self, data):
        """å‘é€æ•°æ®åˆ°å®¢æˆ·ç«¯"""
        try:
            self.websocket.send(json.dumps(data))
        except Exception as e:
            logger.error(f"å‘é€åˆ°å®¢æˆ·ç«¯å¤±è´¥: {e}")

    def append_video(self, frame_b64):
        """å‘é€è§†é¢‘å¸§ - å‚è€ƒ vad_dash.py"""
        if not self.is_active or not self.conversation:
            return False

        try:
            # æ§åˆ¶å‘é€é¢‘ç‡ï¼ˆ2fpsï¼‰
            current_time = time.time() * 1000
            if current_time - self.last_frame_time < FRAME_INTERVAL_MS:
                return True  # è·³è¿‡ï¼Œé¢‘ç‡å¤ªé«˜

            self.conversation.append_video(frame_b64)
            self.last_frame_time = current_time
            return True
        except Exception as e:
            logger.error(f"å‘é€è§†é¢‘å¸§å¤±è´¥: {e}")
            return False

    def append_audio(self, audio_b64):
        """å‘é€éŸ³é¢‘æ•°æ® - å‚è€ƒ vad_dash.py"""
        if not self.is_active or not self.conversation:
            return False

        try:
            self.conversation.append_audio(audio_b64)
            return True
        except Exception as e:
            logger.error(f"å‘é€éŸ³é¢‘å¤±è´¥: {e}")
            return False

    def close(self):
        """å…³é—­ä¼šè¯"""
        if self.conversation:
            try:
                self.conversation.close()
                self.is_active = False
                logger.info(f"ä¼šè¯ {self.session_id} å·²å…³é—­")
            except Exception as e:
                logger.error(f"å…³é—­ä¼šè¯å¤±è´¥: {e}")


def process_video_frame(frame_data):
    """å¤„ç†è§†é¢‘å¸§ - å‚è€ƒ vad_dash.py"""
    try:
        if isinstance(frame_data, str):
            img_bytes = base64.b64decode(frame_data)
        else:
            img_bytes = frame_data

        # å°è¯•ä½œä¸ºå›¾åƒè§£ç 
        nparr = np.frombuffer(img_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if frame is None:
            # å°è¯•ä½œä¸ºè§†é¢‘æ–‡ä»¶
            temp_path = os.path.join(OUTPUT_DIR, f"temp_{os.getpid()}.webm")
            with open(temp_path, 'wb') as f:
                f.write(img_bytes)

            cap = cv2.VideoCapture(temp_path)
            ret, frame = cap.read()
            cap.release()
            os.remove(temp_path)

            if not ret:
                return None

        # è°ƒæ•´åˆ†è¾¨ç‡åˆ° 720pï¼ˆå‚è€ƒ vad_dash.pyï¼‰
        height, width = frame.shape[:2]
        if height > 720:
            scale = 720.0 / height
            frame = cv2.resize(frame, (int(width * scale), 720))

        # ç¼–ç ä¸º JPEG
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 70]
        success, encoded = cv2.imencode('.jpg', frame, encode_param)

        if not success:
            return None

        # æ£€æŸ¥å¤§å°ï¼ˆæœ€å¤§ 500KBï¼‰
        if len(encoded.tobytes()) > 500 * 1024:
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 50]
            success, encoded = cv2.imencode('.jpg', frame, encode_param)

        return base64.b64encode(encoded.tobytes()).decode('ascii')

    except Exception as e:
        logger.error(f"è§†é¢‘å¸§å¤„ç†é”™è¯¯: {e}")
        return None


@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "ok",
        "service": "Qwen-Omni Video Service (Realtime)",
        "active_sessions": len(sessions),
        "mode": "realtime_stream"
    })


@sock.route('/ws/video')
def websocket_video(ws):
    """
    WebSocket å®æ—¶è§†é¢‘åˆ†æ
    å®¢æˆ·ç«¯å‘é€: {type: 'video', data: base64} æˆ– {type: 'audio', data: base64}
    æœåŠ¡ç«¯è¿”å›: {type: 'text.delta', text: '...'} æˆ– {type: 'audio.delta', audio: '...'}
    """
    session_id = f"ws_{int(time.time() * 1000)}"
    logger.info(f"æ–°çš„ WebSocket è¿æ¥: {session_id}")

    try:
        # åˆ›å»ºä¼šè¯
        session = RealtimeVideoSession(session_id, ws)

        if not session.start():
            ws.send(json.dumps({'type': 'error', 'message': 'ä¼šè¯å¯åŠ¨å¤±è´¥'}))
            return

        with session_lock:
            sessions[session_id] = session

        # å‘é€æ¬¢è¿æ¶ˆæ¯
        ws.send(json.dumps({
            'type': 'ready',
            'session_id': session_id,
            'message': 'å®æ—¶è§†é¢‘åˆ†æä¼šè¯å·²å»ºç«‹'
        }))

        # æ¥æ”¶å®¢æˆ·ç«¯æ¶ˆæ¯
        while True:
            message = ws.receive()
            if message is None:
                break

            try:
                data = json.loads(message)
                msg_type = data.get('type')

                if msg_type == 'video':
                    # æ¥æ”¶è§†é¢‘å¸§
                    frame_b64 = data.get('data')
                    if frame_b64:
                        # å¤„ç†è§†é¢‘å¸§
                        processed = process_video_frame(frame_b64)
                        if processed:
                            session.append_video(processed)

                elif msg_type == 'audio':
                    # æ¥æ”¶éŸ³é¢‘æ•°æ®
                    audio_b64 = data.get('data')
                    if audio_b64:
                        session.append_audio(audio_b64)

                elif msg_type == 'close':
                    break

            except Exception as e:
                logger.error(f"å¤„ç†æ¶ˆæ¯é”™è¯¯: {e}")

    except Exception as e:
        logger.error(f"WebSocket é”™è¯¯: {e}")

    finally:
        # æ¸…ç†ä¼šè¯
        if session_id in sessions:
            with session_lock:
                sessions[session_id].close()
                del sessions[session_id]

        logger.info(f"WebSocket è¿æ¥å…³é—­: {session_id}")


if __name__ == '__main__':
    logger.info("=" * 60)
    logger.info("Qwen-Omni è§†é¢‘æœåŠ¡å¯åŠ¨ä¸­ï¼ˆå®æ—¶æµå¼ç‰ˆï¼‰...")
    logger.info("=" * 60)
    logger.info("")
    logger.info("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
    logger.info("ğŸ“ åœ°å€: http://0.0.0.0:5003")
    logger.info("ğŸ“¹ è§†é¢‘åˆ†æ: Qwen3-Omni-Flash-Realtime")
    logger.info("ğŸ”„ æ¨¡å¼: å®æ—¶æµå¼å¤„ç†ï¼ˆWebSocketï¼‰")
    logger.info("ğŸ¤ VAD: å¯ç”¨ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­éŸ³ï¼‰")
    logger.info("")
    logger.info("ğŸ“š WebSocket ç«¯ç‚¹:")
    logger.info("   ws://localhost:5003/ws/video - å®æ—¶è§†é¢‘æµ")
    logger.info("")
    logger.info("ğŸ’¡ å‚è€ƒ: vad_dash.py è®¾è®¡")
    logger.info("=" * 60)

    app.run(host='0.0.0.0', port=5003, debug=False, threaded=True)
